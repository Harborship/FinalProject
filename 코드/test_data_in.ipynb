{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_data_in.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVMgInMCOyrG","executionInfo":{"status":"ok","timestamp":1658982497520,"user_tz":-540,"elapsed":21508,"user":{"displayName":"harborship","userId":"14186759060292545698"}},"outputId":"14c8b4a4-8fd7-4c7c-fccb-059222f474a4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from numpy import array\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import string\n","import os\n","from PIL import Image\n","from time import time\n","from keras.layers import Dense, Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from keras.layers.merge import add\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.inception_v3 import preprocess_input\n","from tensorflow.keras.utils import img_to_array\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import keras\n","from keras.models import Model\n","from keras import Input, layers\n","from tqdm import tqdm"],"metadata":{"id":"P8Md24MkNA4F","executionInfo":{"status":"ok","timestamp":1658982501056,"user_tz":-540,"elapsed":3544,"user":{"displayName":"harborship","userId":"14186759060292545698"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Gzn-Dv5TM8Zi","executionInfo":{"status":"ok","timestamp":1658982506038,"user_tz":-540,"elapsed":4990,"user":{"displayName":"harborship","userId":"14186759060292545698"}}},"outputs":[],"source":["object_model=load_model('/content/drive/MyDrive/5조/모델/07.21 객체검출 모델/best_model.h5')\n","scenery_model=load_model('/content/drive/MyDrive/5조/모델/07.21 배경검출 모델/best_model.h5')"]},{"cell_type":"code","source":["# 이미지의 벡터화를 진행하는 코드\n","\n","# Load the inception v3 model\n","model_v3 = InceptionV3(weights='imagenet')\n","\n","# Create a new model, by removing the last layer (output layer) from the inception v3\n","model_new = Model(model_v3.input, model_v3.layers[-2].output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqRygQveNEGk","executionInfo":{"status":"ok","timestamp":1658455049447,"user_tz":-540,"elapsed":4291,"user":{"displayName":"groupfive1 multi","userId":"14653379220115847940"}},"outputId":"27d128c3-3c8a-4dad-c8ad-c7e9530aebb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n","96116736/96112376 [==============================] - 1s 0us/step\n","96124928/96112376 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["# Function to encode a given image into a vector of size (2048, )\n","def encode(image_path):\n","    img = keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n","    # Convert image to numpy array of 3-dimensions\n","    x = img_to_array(img)\n","    # Add one more dimension\n","    x = np.expand_dims(x, axis=0)\n","    # preprocess the images using preprocess_input() from inception module\n","    x = preprocess_input(x)\n","    fea_vec = model_new.predict(x) # Get the encoding vector for the image\n","    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n","    return fea_vec   # 이 데이터가 input data로 사용됨"],"metadata":{"id":"GP6aOBD0NEI2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path='/content/temp1/'    # 분석할 이미지가 있는 디렉토리 지정 필요\n","data=[]\n","for image in tqdm(  ):\n","  path=image_path+image     \n","  data.append( np.array(encode(path)) )\n","\n","data=np.array(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6srjtkUGNYcU","executionInfo":{"status":"ok","timestamp":1657862472838,"user_tz":-540,"elapsed":888222,"user":{"displayName":"groupfive1 multi","userId":"14653379220115847940"}},"outputId":"6fe85652-2e87-469d-d34c-b7383302ed24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3048/3048 [14:48<00:00,  3.43it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.5589647 , 0.2209115 , 0.10350508, ..., 0.61137414, 0.29394227,\n","        0.0053378 ],\n","       [0.15149772, 1.1019528 , 0.66359836, ..., 0.38602915, 0.16809331,\n","        0.470982  ],\n","       [0.34664848, 0.2418502 , 1.325381  , ..., 0.09563419, 0.12009779,\n","        0.09665566],\n","       ...,\n","       [0.23977375, 0.18751779, 1.8036178 , ..., 0.9742502 , 0.6386868 ,\n","        1.3077613 ],\n","       [0.05636256, 0.36781067, 0.5337228 , ..., 0.5544225 , 0.7525874 ,\n","        0.        ],\n","       [0.16076939, 0.257062  , 0.01088384, ..., 0.06123613, 0.440277  ,\n","        0.18932901]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# 객체검출 결과\n","y_object_pred=[]\n","label=object_model.predict(data.reshape(-1,2048))\n","for sample in label:\n","  y_object_pred.append([1 if i>=0.5 else 0 for i in sample ] )\n","y_object_pred = np.array(y_object_pred)"],"metadata":{"id":"Zjg0a5njNGd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 풍경검출 결과\n","y_scenery_pred=[]\n","label=scenery_model.predict(data.reshape(-1,2048)))\n","for sample in label:\n","  y_scenery_pred.append([1 if i>=0.5 else 0 for i in sample ] )\n","y_scenery_pred = np.array(y_scenery_pred)"],"metadata":{"id":"EOdEUyz_ptLt"},"execution_count":null,"outputs":[]}]}